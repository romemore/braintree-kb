# RAG et Context

Techniques de gestion du contexte long, retrieval-augmented generation et stratégies d'inférence pour dépasser les limites des fenêtres de contexte.

## Fiches

| Date | Fiche | TL;DR |
|------|-------|-------|
| 2026-02-11 | [Recursive Language Models : dépasser les limites de la fenêtre de contexte](2026-02-11-recursive-language-models.md) | Les RLM permettent aux LLM de traiter des entrées 100x plus longues que leur fenêtre de contexte en externalisant le prompt dans un environnement REPL Python exploré récursivement. RLM-Qwen3-8B surpasse Qwen3-8B de 28,3% et approche GPT-5. |

## Thèmes récurrents
- Externalisation du contexte dans un environnement programmatique (REPL)
- Récursion comme stratégie d'inférence pour le contexte long
- Stratégies émergentes : peeking, grepping, partition+map, summarization
- Post-entraînement de modèles nativement récursifs

---
*Mis à jour le 2026-02-11*
