# SLM & Données

Small Language Models, curation de données d'entraînement, données synthétiques et approches souveraines pour l'IA décentralisée.

## Fiches

| Date | Fiche | TL;DR |
|------|-------|-------|
| 2026-02-18 | [Playas & Anastasia Stasenko : SLM, données synthétiques et open data souverain](2026-02-18-anastasia-stasenko-playas-slm-donnees.md) | BaguetteTron (320M params) de Playas démontre qu'un SLM entraîné sur 200B tokens synthétiques issus de 50K articles Wikipédia surpasse des modèles entraînés sur 10× plus de données — la qualité de la donnée par provenance prime sur la quantité. |

## Thèmes récurrents
- Données par provenance vs filtrage à posteriori du Common Crawl
- Données synthétiques structurées (non-naïves) avec pipelines de vérification
- SLM décentralisés et souverains pour les entreprises
- Model collapse et comment l'éviter
- Domaines semi-vérifiables (jurisprudence, finance, télécom) comme prochain enjeu
